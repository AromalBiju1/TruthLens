import io
from PIL import Image
import torch
from transformers import CLIPProcessor, CLIPModel

_device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
_model = None
_processor = None

REAL_PROMPTS = [
    "a real photograph taken by a camera",
    "a genuine photo of a real person",
    "an authentic unedited image",
]

FAKE_PROMPTS = [
    "an AI generated image",
    "a deepfake manipulated photo",
    "a synthetic computer generated face",
    "an image generated by artificial intelligence",
]

def _load_model():
    global _model, _processor
    if _model is not None:
        return
    print(f"[TruthLens] Loading CLIP on {_device}...")
    _model = CLIPModel.from_pretrained("openai/clip-vit-large-patch14")
    _processor = CLIPProcessor.from_pretrained("openai/clip-vit-large-patch14")
    _model = _model.to(_device)
    _model.eval()
    print("[TruthLens] CLIP loaded âœ“")

def run_clip(image_bytes: bytes) -> float:
    _load_model()
    try:
        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        all_prompts = REAL_PROMPTS + FAKE_PROMPTS

        inputs = _processor(
            text=all_prompts,
            images=image,
            return_tensors="pt",
            padding=True
        ).to(_device)

        with torch.no_grad():
            outputs = _model(**inputs)
            probs = torch.softmax(outputs.logits_per_image, dim=1)[0]

        real_score = probs[:len(REAL_PROMPTS)].mean().item()
        fake_score = probs[len(REAL_PROMPTS):].mean().item()

        total = real_score + fake_score + 1e-8
        fake_prob = (fake_score / total) * 100

        return round(fake_prob, 2)

    except Exception as e:
        print(f"[TruthLens] CLIP error: {e}")
        return 50.0